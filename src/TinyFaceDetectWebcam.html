<!DOCTYPE html>
<html>

<head>
    <title>Live Detector</title>
    <script src="../dist/face-api.js"></script>
    <link rel="stylesheet" href="public/styles.css">
    <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.14.1/dist/tf.min.js"></script>
    <script src="html2canvas.js"></script>
    <link href="https://fonts.googleapis.com/css?family=Raleway:700" rel="stylesheet">
</head>

<body>
    <div class="center-content page-container">
        <h5>
            <span id="status" style="text-align: center">Model Loading ...</span>
        </h5>
        
        <div style="position: relative" class="margin">
            <video onplay="onPlay(this)" id="inputVideo" autoplay></video>
            <canvas id="overlay" />
            <canvas id='canvas' />
        </div>
        
        <div>Supported by <a href='https://github.com/justadudewhohacks/face-api.js/'>face-api.js <br></a> </div>
        <br>
        <br>
        <button id="snap">Snap Photo</button>
        </div>
    
    <div id="all" style="float:right" >
        <div id="buttonhappy"> Happy </div>
        <div id="buttonsad"> Sad </div>
        <div id="buttonangry"> Angry </div>
        <div id="buttondisgusted"> Disgusted </div>
        <div id="buttonfear"> Fear </div>
        <div id="buttonsurprise"> Surprise </div>
        <div id="buttonneutral"> Neutral </div>
        <div id="some_div"></div>
    </div>
    
    <style>
        #status {
            font-family: Geneva, Tahoma, Verdana, sans-serif;
            text-align: center;
            font-size: 20px;
        }

        .inline {
            display: inline-block;
        } 
        
        #all {
           margin-top: 50px; 
        }
        #buttonhappy,#buttonsad,#buttonangry,#buttondisgusted,#buttonfear,#buttonsurprise,#buttonneutral{
          text-align:center;
          min-width: 50px;
          margin: 20px 50px 25px 20px;
          padding: 10px;
          background-color: #2ca7de;
          border-radius: 1em;
          font-family: 'Raleway', sans-serif;
            }       
        #buttonhappy:hover,#buttonsad:hover,#buttonangry:hover,#buttondisgusted:hover,#buttonfear:hover,#buttonsurprise:hover,#buttonneutral:hover{
          background-color: #ffe100;
            }   
    </style>
    
    
    <script>
    var timeLeft = 10;
    var elem = document.getElementById('some_div');
    setTimeout('var timerId = setInterval(countdown, 1000)', 5000);

    function countdown() {
        if (timeLeft == -1) {
              timeLeft = 15;  
            doSomething();
        } else {
            elem.innerHTML = timeLeft + ' seconds remaining';
            timeLeft--;
        }
      }    
function doSomething() {
    html2canvas(document.body).then(function(canvas) {
               document.body.appendChild(canvas);
            });
}        
    </script>

    
    <script>
        let sizeType = '200'
        let modelLoaded = false
        var cImg;
        var constraints = {
            audio: false,
            video: {
                width: 576, height: 432
            }
        };
        var EmotionModel;
        var offset_x = 34;
        var offset_y = 20;
        
        var emotion_labels = ["angry", "disgust", "fear", "happy", "sad", "surprise", "neutral"];
        var emotion_colors = ["#ff0000", "#00a800", "#ff4fc1", "#ffe100", "#306eff", "#ff9d00", "#7c7c7c"];

        async function onPlay(videoEl) {
            if (videoEl.paused || videoEl.ended || !modelLoaded)
                return false

            const {
                width, height
            } = faceapi.getMediaDimensions(videoEl)
            const canvas = $('#overlay').get(0)
            canvas.width = width
            canvas.height = height

            const forwardParams = {
                inputSize: (224,224),
            }

            const result = await faceapi.detectAllFaces(videoEl, new faceapi.TinyFaceDetectorOptions(forwardParams))
            console.result

            
            
            if (result.length != 0) {
                const context = canvas.getContext('2d')
                context.drawImage(videoEl, 0, 0, width, height)
                
                let ctx = context;
                ctx.lineWidth = 4;
                ctx.font = "25px Arial"
                ctx.fillText('Result', 0, 0);

                for (var i = 0; i < result.length; i++) {
                    ctx.beginPath();
                    var item = result[i].box;
                    let s_x = Math.floor(item._x+offset_x);
                    if (item.y<offset_y){
                        var s_y = Math.floor(item._y);
                    }
                    else{
                        var s_y = Math.floor(item._y-offset_y);
                    }
                    let s_w = Math.floor(item._width-offset_x);
                    let s_h = Math.floor(item._height);
                    let cT = ctx.getImageData(s_x, s_y, s_w, s_h);
                    cT = preprocess(cT);
                    
                    

                    z = EmotionModel.predict(cT)
                    let index = z.argMax(1).dataSync()[0]
                    let label = emotion_labels[index];
                    ctx.strokeStyle = emotion_colors[index];
                    ctx.rect(s_x, s_y, s_w, s_h);
                    ctx.stroke();
                    ctx.fillStyle = emotion_colors[index];
                    ctx.fillText(label, s_x, s_y);
                    ctx.closePath(); 
                    
                    function doSomething() {
                    alert(label);
                        }   
                }

            }

            
            document.getElementById("snap").addEventListener("click", function() {
	            context.drawImage(videoEl, 0, 0, 640, 480);
                });
            
            
            setTimeout(() => onPlay(videoEl))
            var status = document.getElementById('status');
            status.innerHTML = "Start Detecting yout Emotion ... ";
        }
        async function loadNetWeights(uri) {
            return new Float32Array(await (await fetch(uri)).arrayBuffer())
        }
        
        
        async function createModel(path) {
            let model = await tf.loadModel(path)
            return model
        }
        // load emotion model
        async function loadModel(path) {
            EmotionModel = await createModel(path)
        }

        function preprocess(imgData) {
            return tf.tidy(() => {
                let tensor = tf.fromPixels(imgData).toFloat();

                tensor = tensor.resizeBilinear([100, 100])

                tensor = tf.cast(tensor, 'float32')
                const offset = tf.scalar(255.0);
                // Normalize the image 
                const normalized = tensor.div(offset);
                const batched = normalized.expandDims(0)
                return batched
            })
        }

        function successCallback(stream) {
            var videoEl = $('#inputVideo').get(0)
            videoEl.srcObject = stream;
        }

        function errorCallback(error) {
            alert(error)
            console.log("navigator.getUserMedia error: ", error);
        }

        async function run() {
            const Model_url = '../models/tiny_face_detector/tiny_face_detector_model-weights_manifest.json'
            await faceapi.loadTinyFaceDetectorModel(Model_url)
            modelLoaded = true

            var status = document.getElementById('status');
            status.innerHTML = "Initializing the camera ... ";

            navigator.mediaDevices.getUserMedia(constraints)
                .then(successCallback)
                .catch(errorCallback);

            onPlay($('#inputVideo').get(0))
            $('#loader').hide()
        }

        $(document).ready(function() {
            loadModel('../models/mobilenetv1_models/model.json')
            const sizeTypeSelect = $('#sizeType')
            run()
        })    
    </script>
    
    
    <script>
     document.getElementById("buttonhappy").onclick=function () {
     window.open("https://music.youtube.com/watch?v=q5CUnuE3WRs&list=RDAMVMq5CUnuE3WRs")}
     
     document.getElementById("buttonsad").onclick=function () {
     window.open("https://music.youtube.com/watch?v=viQ_CEiARoE&list=RDAMVMviQ_CEiARoE")}
     
     document.getElementById("buttonangry").onclick=function () {
     window.open("https://music.youtube.com/watch?v=0CY3FRqtwX4&list=RDAMVM0CY3FRqtwX4")}
     
     document.getElementById("buttondisgusted").onclick=function () {
     window.open("https://music.youtube.com/watch?v=TXGNuJ6wIes&list=RDAMVMTXGNuJ6wIes")}
     
     document.getElementById("buttonsurprise").onclick=function () {
     window.open("https://music.youtube.com/watch?v=-RP19fnff_c&list=RDAMVMkxYNseMvCoc") }
     
     document.getElementById("buttonfear").onclick=function () {
     window.open("https://music.youtube.com/watch?v=-WsZ2fUXbZg&list=RDAMVM-WsZ2fUXbZg")}
     
     document.getElementById("buttonneutral").onclick=function () {
     window.open("https://music.youtube.com/watch?v=ZlWQG-DK8t8&list=RDAMVMZlWQG-DK8t8")}
    </script>
     
</body>

</html>